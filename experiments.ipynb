{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Irrigation System Hyperparameter Optimization Study\n",
    "\n",
    "## Overview\n",
    "This notebook implements a comprehensive Bayesian hyperparameter optimization study for a safe reinforcement learning irrigation system. The study focuses on minimizing constraint violation costs while maintaining system safety.\n",
    "\n",
    "## Study Objectives\n",
    "1. **Primary Goal**: Minimize irrigation constraint violation costs\n",
    "2. **Secondary Goal**: Identify most important hyperparameters for performance\n",
    "3. **Safety Goal**: Maintain safe operation under all parameter configurations\n",
    "\n",
    "## Methodology\n",
    "- **Optimizer**: Optuna with Tree-structured Parzen Estimator (TPE)\n",
    "- **Search Strategy**: Progressive multi-phase optimization\n",
    "- **Safety Features**: Checkpointing, memory management, error recovery\n",
    "- **Convergence Detection**: Automatic stopping based on coefficient of variation\n",
    "\n",
    "## Expected Runtime\n",
    "- **Total Trials**: 50-125 (adaptive based on convergence)\n",
    "- **Time per Trial**: ~10-15 minutes (25 epochs each)\n",
    "- **Total Duration**: 8-30 hours depending on convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === IMPORTS AND SETUP ===\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import gc\n",
    "import torch\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "# Import custom modules\n",
    "from water_environment import WaterEnvironment\n",
    "from training import train_agent\n",
    "\n",
    "# Display settings\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(f\"Study started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Optuna version: {optuna.__version__}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DATA SETUP AND VALIDATION ===\n",
    "\n",
    "# Directory configuration\n",
    "folder_path_initial = '/home/egomez/irrigation_project/'\n",
    "folder_path_output = '/scratch/egomez/irrigation_project_output/'\n",
    "data_file = os.path.join(folder_path_initial, 'daily_weather_data.csv')\n",
    "model_directory = os.path.join(folder_path_output, 'models')\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs(model_directory, exist_ok=True)\n",
    "os.makedirs(os.path.join(model_directory, 'optimization'), exist_ok=True)\n",
    "os.makedirs(os.path.join(model_directory, 'test'), exist_ok=True)\n",
    "\n",
    "df = pd.read_csv(data_file)\n",
    "\n",
    "# Study configuration\n",
    "STUDY_CONFIG = {\n",
    "    'max_total_trials': 125,\n",
    "    'phase1_trials': 50,    # Initial exploration\n",
    "    'phase2_trials': 50,    # Refinement  \n",
    "    'phase3_trials': 25,    # Final optimization\n",
    "    'convergence_threshold': 0.05,  # CV threshold for stopping\n",
    "    'checkpoint_frequency': 10,\n",
    "    'memory_cleanup_frequency': 5,\n",
    "}\n",
    "\n",
    "print(f\"\\nStudy Configuration:\")\n",
    "for key, value in STUDY_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(f\"\\nOutput directories:\")\n",
    "print(f\"  Models: {model_directory}\")\n",
    "print(f\"  Optimization: {os.path.join(model_directory, 'optimization')}\")\n",
    "print(f\"  Test: {os.path.join(model_directory, 'test')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_env_params = {\n",
    "    'weather_data': df, \n",
    "    'n_days_ahead': 7\n",
    "}\n",
    "\n",
    "base_agent_params = {\n",
    "    'polyak':          0.999,\n",
    "    'gamma':           0.99,\n",
    "    'model_type':      'DDPGLagrangian',\n",
    "    'hidden_layers':   [256, 256],\n",
    "    'chance_const':    0.95,\n",
    "    'actor_lr':        1e-5,  # Will be optimized\n",
    "    'critic_lr':       1e-4,  # Will be optimized\n",
    "    'cost_critic_lr':  1e-3,  # Will be optimized\n",
    "    'KP':              0.01,  # Will be optimized\n",
    "    'KI':              0.01,  # Will be optimized\n",
    "    'KD':              0.0,   # Will be optimized\n",
    "    'safe_buffer':     True,\n",
    "}\n",
    "\n",
    "base_training_params = {\n",
    "    'num_epochs': 500,  # Reduced during optimization\n",
    "    'sample_episode_num': 20,\n",
    "    'episode_rerun_num': 20,\n",
    "    'evaluate_episode_num': 15,\n",
    "    'plot_save_frequency': 100,\n",
    "    'max_episode_steps': 1000,\n",
    "    'batch_size': 512,\n",
    "    'seed': 0,\n",
    "    'device': \"gpu\",\n",
    "    'threads': 1,\n",
    "    'reset_epochs': {100, 200, 300, 400}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === STUDY UTILITIES AND VALIDATION ===\n",
    "\n",
    "def validate_setup():\n",
    "    \"\"\"Validate that all components are properly configured.\"\"\"\n",
    "    print(\"=== SETUP VALIDATION ===\")\n",
    "    \n",
    "    validation_results = {\n",
    "        'data_file': os.path.exists(data_file),\n",
    "        'output_dir': os.path.exists(model_directory),\n",
    "        'gpu_available': torch.cuda.is_available() if 'gpu' in base_training_params['device'] else True,\n",
    "        'modules_importable': True  # Already imported successfully\n",
    "    }\n",
    "    \n",
    "    print(\"Component Status:\")\n",
    "    for component, status in validation_results.items():\n",
    "        status_icon = \"‚úÖ\" if status else \"‚ùå\"\n",
    "        print(f\"  {component}: {status_icon}\")\n",
    "    \n",
    "    # Check disk space\n",
    "    try:\n",
    "        import shutil\n",
    "        total, used, free = shutil.disk_usage(folder_path_output)\n",
    "        free_gb = free / (1024**3)\n",
    "        print(f\"  disk_space: ‚úÖ ({free_gb:.1f} GB free)\")\n",
    "        if free_gb < 10:\n",
    "            print(\"    ‚ö†Ô∏è  Warning: Less than 10GB free space available\")\n",
    "    except:\n",
    "        print(f\"  disk_space: ‚ö†Ô∏è  (Could not check)\")\n",
    "    \n",
    "    # Check memory\n",
    "    if torch.cuda.is_available():\n",
    "        try:\n",
    "            gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "            print(f\"  gpu_memory: ‚úÖ ({gpu_memory:.1f} GB)\")\n",
    "        except:\n",
    "            print(f\"  gpu_memory: ‚ö†Ô∏è  (Could not check)\")\n",
    "    \n",
    "    all_valid = all(validation_results.values())\n",
    "    print(f\"\\nOverall Status: {'‚úÖ Ready for optimization' if all_valid else '‚ùå Issues detected'}\")\n",
    "    \n",
    "    return all_valid\n",
    "\n",
    "def cleanup_memory():\n",
    "    \"\"\"Clean up GPU and system memory.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "def get_study_status():\n",
    "    \"\"\"Get current study progress.\"\"\"\n",
    "    study_file = os.path.join(model_directory, 'study_checkpoint.pkl')\n",
    "    try:\n",
    "        with open(study_file, 'rb') as f:\n",
    "            study = pickle.load(f)\n",
    "        \n",
    "        completed_trials = len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE])\n",
    "        failed_trials = len([t for t in study.trials if t.state == optuna.trial.TrialState.FAIL])\n",
    "        \n",
    "        print(f\"=== STUDY STATUS ===\")\n",
    "        print(f\"Total trials: {len(study.trials)}\")\n",
    "        print(f\"Completed: {completed_trials}\")\n",
    "        print(f\"Failed: {failed_trials}\")\n",
    "        \n",
    "        if study.best_trial:\n",
    "            print(f\"Best cost: {study.best_value:.4f}\")\n",
    "            print(f\"Best trial: #{study.best_trial.number}\")\n",
    "        \n",
    "        return study, completed_trials, failed_trials\n",
    "    except FileNotFoundError:\n",
    "        print(\"=== STUDY STATUS ===\")\n",
    "        print(\"No existing study found - will start fresh\")\n",
    "        return None, 0, 0\n",
    "\n",
    "def estimate_remaining_time(completed_trials, target_trials, avg_time_per_trial=12):\n",
    "    \"\"\"Estimate remaining optimization time.\"\"\"\n",
    "    remaining_trials = max(0, target_trials - completed_trials)\n",
    "    remaining_minutes = remaining_trials * avg_time_per_trial\n",
    "    remaining_hours = remaining_minutes / 60\n",
    "    \n",
    "    print(f\"\\n=== TIME ESTIMATION ===\")\n",
    "    print(f\"Completed trials: {completed_trials}\")\n",
    "    print(f\"Target trials: {target_trials}\")\n",
    "    print(f\"Remaining trials: {remaining_trials}\")\n",
    "    print(f\"Estimated time remaining: {remaining_hours:.1f} hours ({remaining_minutes:.0f} minutes)\")\n",
    "    \n",
    "    if remaining_hours > 24:\n",
    "        print(f\"  ‚âà {remaining_hours/24:.1f} days\")\n",
    "    \n",
    "    return remaining_hours\n",
    "\n",
    "# Run validation\n",
    "validation_passed = validate_setup()\n",
    "\n",
    "# Check existing study status\n",
    "existing_study, completed_trials, failed_trials = get_study_status()\n",
    "\n",
    "# Estimate time for full study\n",
    "target_trials = STUDY_CONFIG['max_total_trials']\n",
    "if existing_study:\n",
    "    remaining_time = estimate_remaining_time(completed_trials, target_trials)\n",
    "else:\n",
    "    print(f\"\\n=== TIME ESTIMATION ===\")\n",
    "    print(f\"New study - estimated total time: {target_trials * 12 / 60:.1f} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"Optuna objective function for Bayesian hyperparameter optimization.\"\"\"\n",
    "    import gc\n",
    "    import torch\n",
    "    \n",
    "    # Clear GPU memory at start of each trial\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    # Sample hyperparameters\n",
    "    polyak = trial.suggest_float('polyak', 0.9, 0.999)\n",
    "    actor_lr = trial.suggest_float('actor_lr', 1e-6, 1e-3, log=True)\n",
    "    critic_lr = trial.suggest_float('critic_lr', 1e-5, 1e-3, log=True)\n",
    "    cost_critic_lr = trial.suggest_float('cost_critic_lr', 1e-5, 1e-2, log=True)\n",
    "    kp = trial.suggest_float('KP', 0.001, 10, log=True)\n",
    "    ki = trial.suggest_float('KI', 0.001, 1, log=True)\n",
    "    kd = trial.suggest_float('KD', 0.0, 0.01)\n",
    "    \n",
    "    # Create agent parameters with sampled values\n",
    "    agent_params = base_agent_params.copy()\n",
    "    agent_params.update({\n",
    "        'polyak': polyak,\n",
    "        'actor_lr': actor_lr,\n",
    "        'critic_lr': critic_lr,\n",
    "        'cost_critic_lr': cost_critic_lr,\n",
    "        'KP': kp,\n",
    "        'KI': ki,\n",
    "        'KD': kd,\n",
    "    })\n",
    "    \n",
    "    # Create shorter training for optimization (faster trials)\n",
    "    training_params = base_training_params.copy()\n",
    "    training_params.update({\n",
    "        'num_epochs': 25,  # Shorter for stability\n",
    "        'plot_save_frequency': 1000,  # Disable plotting during optimization\n",
    "        'evaluate_episode_num': 1  # Reduce evaluation episodes\n",
    "    })\n",
    "    \n",
    "    # Create unique identifier for this trial\n",
    "    identifier = f\"trial_{trial.number}_actor{actor_lr:.1e}_critic{critic_lr:.1e}_kp{kp:.3f}\"\n",
    "    exp_dir = os.path.join(model_directory, 'optimization', identifier)\n",
    "    os.makedirs(exp_dir, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        print(f\"Starting trial {trial.number}...\")\n",
    "        \n",
    "        # Create environment\n",
    "        env = WaterEnvironment(**base_env_params)\n",
    "        agent_params.update({\n",
    "            'env': env,\n",
    "            'chkpt_dir': exp_dir,\n",
    "        })\n",
    "        \n",
    "        # Train agent and get performance metrics\n",
    "        results = train_agent(base_env_params, agent_params, training_params, exp_dir, identifier)\n",
    "        \n",
    "        # Extract cost metrics\n",
    "        total_costs = results['total_costs']\n",
    "        avg_cost = results['avg_cost_per_episode']\n",
    "        \n",
    "        # For cost minimization, return negative cost (since Optuna maximizes)\n",
    "        objective_value = -avg_cost\n",
    "        \n",
    "        # Log trial results\n",
    "        print(f\"Trial {trial.number} completed: avg_cost={avg_cost:.3f}, total_costs={total_costs:.3f}\")\n",
    "        \n",
    "        # Clean up\n",
    "        del env, results\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        return objective_value\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Trial {trial.number} failed with error: {e}\")\n",
    "        print(f\"Trial parameters: {trial.params}\")\n",
    "        \n",
    "        # Clean up on error\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        return -1000  # Return very poor score for failed trials\n",
    "\n",
    "def run_bayesian_optimization(n_trials=10, save_every=5):\n",
    "    \"\"\"Run Bayesian optimization with checkpointing.\"\"\"\n",
    "    import pickle\n",
    "    \n",
    "    study_file = os.path.join(model_directory, 'study_checkpoint.pkl')\n",
    "    \n",
    "    # Try to load existing study\n",
    "    try:\n",
    "        with open(study_file, 'rb') as f:\n",
    "            study = pickle.load(f)\n",
    "        print(f\"Loaded existing study with {len(study.trials)} trials\")\n",
    "        start_trial = len(study.trials)\n",
    "    except FileNotFoundError:\n",
    "        # Create new study\n",
    "        study = optuna.create_study(\n",
    "            direction='maximize',\n",
    "            sampler=TPESampler(seed=42),\n",
    "            study_name='irrigation_cost_minimization'\n",
    "        )\n",
    "        start_trial = 0\n",
    "        print(\"Created new optimization study\")\n",
    "    \n",
    "    print(f\"Running {n_trials} trials (starting from trial {start_trial})...\")\n",
    "    print(\"Objective: Minimize constraint violation costs\")\n",
    "    \n",
    "    try:\n",
    "        for i in range(n_trials):\n",
    "            print(f\"\\n--- Running trial {start_trial + i + 1}/{start_trial + n_trials} ---\")\n",
    "            \n",
    "            # Run single trial\n",
    "            study.optimize(objective, n_trials=1)\n",
    "            \n",
    "            # Save checkpoint every few trials\n",
    "            if (i + 1) % save_every == 0 or i == n_trials - 1:\n",
    "                with open(study_file, 'wb') as f:\n",
    "                    pickle.dump(study, f)\n",
    "                print(f\"Checkpoint saved after {len(study.trials)} trials\")\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Optimization interrupted by user\")\n",
    "    except Exception as e:\n",
    "        print(f\"Optimization failed: {e}\")\n",
    "    \n",
    "    # Save final study\n",
    "    with open(study_file, 'wb') as f:\n",
    "        pickle.dump(study, f)\n",
    "    \n",
    "    # Print results\n",
    "    if study.trials:\n",
    "        print(\"\\nOptimization completed!\")\n",
    "        print(f\"Total trials: {len(study.trials)}\")\n",
    "        print(f\"Best trial: {study.best_trial.number}\")\n",
    "        print(f\"Best objective value: {study.best_value:.3f}\")\n",
    "        print(f\"Best average cost: {-study.best_value:.3f}\")\n",
    "        print(\"\\nBest parameters:\")\n",
    "        for key, value in study.best_params.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "    \n",
    "    return study\n",
    "\n",
    "# Safe usage - start with fewer trials\n",
    "# study = run_bayesian_optimization(n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_study_checkpoint():\n",
    "    \"\"\"Load saved study from checkpoint.\"\"\"\n",
    "    import pickle\n",
    "    study_file = os.path.join(model_directory, 'study_checkpoint.pkl')\n",
    "    try:\n",
    "        with open(study_file, 'rb') as f:\n",
    "            study = pickle.load(f)\n",
    "        print(f\"Loaded study with {len(study.trials)} trials\")\n",
    "        return study\n",
    "    except FileNotFoundError:\n",
    "        print(\"No checkpoint found\")\n",
    "        return None\n",
    "\n",
    "def analyze_optimization_results(study):\n",
    "    \"\"\"Analyze and visualize optimization results for cost minimization.\"\"\"\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    if not study or not study.trials:\n",
    "        print(\"No study data to analyze\")\n",
    "        return None\n",
    "    \n",
    "    # Get cost values directly (no conversion needed since we minimize costs directly)\n",
    "    trials = study.trials\n",
    "    cost_values = [t.value for t in trials if t.value is not None and t.state == optuna.trial.TrialState.COMPLETE]\n",
    "    \n",
    "    if not cost_values:\n",
    "        print(\"No completed trials to analyze\")\n",
    "        return None\n",
    "    \n",
    "    # Plot optimization history\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # 1. Cost minimization history\n",
    "    axes[0, 0].plot(cost_values)\n",
    "    axes[0, 0].set_title('Cost Minimization Progress')\n",
    "    axes[0, 0].set_xlabel('Trial')\n",
    "    axes[0, 0].set_ylabel('Average Cost per Episode')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    if study.best_value is not None:\n",
    "        best_cost = study.best_value  # Direct cost value (no conversion)\n",
    "        axes[0, 0].axhline(best_cost, color='red', linestyle='--', \n",
    "                          label=f'Best Cost: {best_cost:.3f}')\n",
    "        axes[0, 0].legend()\n",
    "    \n",
    "    # 2. Parameter importance\n",
    "    try:\n",
    "        if len(cost_values) > 3:  # Need multiple trials for importance\n",
    "            importance = optuna.importance.get_param_importances(study)\n",
    "            params = list(importance.keys())\n",
    "            importances = list(importance.values())\n",
    "            \n",
    "            axes[0, 1].barh(params, importances)\n",
    "            axes[0, 1].set_title('Parameter Importance')\n",
    "            axes[0, 1].set_xlabel('Importance')\n",
    "        else:\n",
    "            axes[0, 1].text(0.5, 0.5, 'Need more trials\\nfor importance analysis', \n",
    "                            ha='center', va='center', transform=axes[0, 1].transAxes)\n",
    "    except:\n",
    "        axes[0, 1].text(0.5, 0.5, 'Parameter importance\\nnot available', \n",
    "                        ha='center', va='center', transform=axes[0, 1].transAxes)\n",
    "    \n",
    "    # 3. Best parameters table\n",
    "    if study.best_params:\n",
    "        best_params = study.best_params\n",
    "        param_names = list(best_params.keys())\n",
    "        param_values = [f\"{best_params[p]:.4f}\" if isinstance(best_params[p], float) \n",
    "                       else str(best_params[p]) for p in param_names]\n",
    "        \n",
    "        axes[1, 0].axis('tight')\n",
    "        axes[1, 0].axis('off')\n",
    "        table = axes[1, 0].table(cellText=[[n, v] for n, v in zip(param_names, param_values)],\n",
    "                                colLabels=['Parameter', 'Best Value'],\n",
    "                                cellLoc='left',\n",
    "                                loc='center')\n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(9)\n",
    "        axes[1, 0].set_title(f'Best Parameters (Cost: {best_cost:.3f})')\n",
    "    else:\n",
    "        axes[1, 0].text(0.5, 0.5, 'No best parameters\\navailable', \n",
    "                        ha='center', va='center', transform=axes[1, 0].transAxes)\n",
    "    \n",
    "    # 4. Distribution of costs\n",
    "    if len(cost_values) > 1:\n",
    "        axes[1, 1].hist(cost_values, bins=min(20, len(cost_values)), alpha=0.7, edgecolor='black')\n",
    "        if study.best_value is not None:\n",
    "            axes[1, 1].axvline(best_cost, color='red', linestyle='--', \n",
    "          )                   label=f'Best: {best_cost:.3f}')\n",
    "            axes[1, 1].legend()\n",
    "    else:\n",
    "        axes[1, 1].text(0.5, 0.5, 'Need more trials\\nfor distribution', \n",
    "                        ha='center', va='center', transform=axes[1, 1].transAxes)\n",
    "    \n",
    "    axes[1, 1].set_title('Distribution of Average Costs')\n",
    "    axes[1, 1].set_xlabel('Average Cost per Episode')\n",
    "    axes[1, 1].set_ylabel('Frequency')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    if study.best_value is not None:\n",
    "        print(\"\\n=== COST MINIMIZATION SUMMARY ===\")\n",
    "        print(f\"Total trials: {len(study.trials)}\")\n",
    "        print(f\"Completed trials: {len(cost_values)}\")\n",
    "        print(f\"Best (minimum) cost: {best_cost:.4f}\")\n",
    "        if len(cost_values) > 1:\n",
    "            print(f\"Worst (maximum) cost: {max(cost_values):.4f}\")\n",
    "            print(f\"Mean cost across trials: {np.mean(cost_values):.4f}\")\n",
    "            print(f\"Std cost across trials: {np.std(cost_values):.4f}\")\n",
    "            print(f\"Cost improvement: {max(cost_values) - best_cost:.4f}\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def run_single_trial_test():\n",
    "    \"\"\"Test a single trial to check if setup works.\"\"\"\n",
    "    print(\"Running single trial test...\")\n",
    "    \n",
    "    # Use default parameters for test\n",
    "    test_params = base_agent_params.copy()\n",
    "    test_training_params = base_training_params.copy()\n",
    "    test_training_params.update({\n",
    "        'num_epochs': 5,  # Very short test\n",
    "        'plot_save_frequency': 1000\n",
    "    })\n",
    "    \n",
    "    identifier = \"single_trial_test\"\n",
    "    exp_dir = os.path.join(model_directory, 'test', identifier)\n",
    "    os.makedirs(exp_dir, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        env = WaterEnvironment(**base_env_params)\n",
    "        test_params.update({\n",
    "            'env': env,\n",
    "            'chkpt_dir': exp_dir,\n",
    "        })\n",
    "        \n",
    "        results = train_agent(base_env_params, test_params, test_training_params, exp_dir, identifier)\n",
    "        print(f\"Test successful! Cost: {results['avg_cost_per_episode']:.3f}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Test failed: {e}\")\n",
    "        return False\n",
    "\n",
    "# Recovery tools - uncomment as needed:\n",
    "# study = load_study_checkpoint()  # Load previous progress\n",
    "# test_success = run_single_trial_test()  # Test basic functionality\n",
    "# study = run_bayesian_optimization(n_trials=3)  # Start small\n",
    "# analyze_optimization_results(study)  # Analyze results\n",
    "    print(\"- Verify environment variables are set correctly\")\n",
    "    print(\"- Confirm network connectivity if required\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === EXECUTE COMPREHENSIVE STUDY ===\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéØ IRRIGATION HYPERPARAMETER OPTIMIZATION STUDY\")\n",
    "print(\"=\"*60)\n",
    "print(\"Select your execution option by uncommenting ONE of the lines below:\")\n",
    "print(\"\")\n",
    "\n",
    "# === EXECUTION OPTIONS ===\n",
    "\n",
    "# Option 1: Run the complete comprehensive study (RECOMMENDED)\n",
    "# This will run the full multi-phase optimization with 50-125 trials\n",
    "# Estimated time: 8-30 hours depending on convergence\n",
    "print(\"Option 1: Complete Study (Recommended)\")\n",
    "print(\"  Uncomment: study = run_comprehensive_study()\")\n",
    "study = run_comprehensive_study()\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "# Option 2: Quick test and small optimization (TESTING)\n",
    "# This will run a quick test followed by a small optimization\n",
    "print(\"Option 2: Quick Test + Small Optimization\")\n",
    "print(\"  Uncomment the lines below:\")\n",
    "# test_success = run_single_trial_test()\n",
    "# if test_success:\n",
    "#     study = run_bayesian_optimization(n_trials=5)\n",
    "#     analyze_optimization_results(study)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "# Option 3: Individual components (DEBUGGING)\n",
    "# Run specific components individually for testing/debugging\n",
    "print(\"Option 3: Individual Components\")\n",
    "print(\"  Uncomment any of these lines:\")\n",
    "# test_success = run_single_trial_test()                    # Quick functionality test (2-3 minutes)\n",
    "# study = run_bayesian_optimization(n_trials=10)            # Small optimization run (2-3 hours)\n",
    "# study = load_study_checkpoint()                           # Load existing progress\n",
    "# analyze_optimization_results(study)                       # Analyze current results\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "# Option 4: Resume existing study (if you have a checkpoint)\n",
    "print(\"Option 4: Resume/Analyze Existing Study\")\n",
    "print(\"  Uncomment the lines below:\")\n",
    "# study = load_study_checkpoint()\n",
    "# if study:\n",
    "#     analyze_optimization_results(study)\n",
    "#     print(f\"\\\\nStudy has {len(study.trials)} trials. To continue:\")\n",
    "#     print(\"  study = run_bayesian_optimization(n_trials=25)\")\n",
    "# else:\n",
    "#     print(\"No existing study found. Start with Option 1 or 2.\")\n",
    "\n",
    "print(\"\")\n",
    "print(\"=\"*60)\n",
    "print(\"üìñ QUICK START INSTRUCTIONS:\")\n",
    "print(\"1. For first-time users: Start with Option 2 (Quick Test)\")\n",
    "print(\"2. For full optimization: Use Option 1 (Complete Study)\")\n",
    "print(\"3. To resume previous work: Use Option 4\")\n",
    "print(\"\")\n",
    "print(\"‚ö†Ô∏è  IMPORTANT: Only uncomment ONE option at a time!\")\n",
    "print(\"üí° TIP: Test with Option 2 first to verify everything works\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Show current system status\n",
    "print(f\"\\nüìä CURRENT SYSTEM STATUS:\")\n",
    "print(f\"  Device: {base_training_params['device'].upper()}\")\n",
    "print(f\"  Validation: {'‚úÖ PASSED' if validation_passed else '‚ùå FAILED'}\")\n",
    "if existing_study:\n",
    "    print(f\"  Existing trials: {len(existing_study.trials)} (best cost: {existing_study.best_value:.4f})\")\n",
    "else:\n",
    "    print(f\"  Existing trials: None (fresh start)\")\n",
    "print(f\"  Ready to start: {'‚úÖ YES' if validation_passed else '‚ùå NO (fix validation issues first)'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "safety-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
