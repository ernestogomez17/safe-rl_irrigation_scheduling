{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from collections import defaultdict, OrderedDict\n",
    "from scipy.signal import savgol_filter\n",
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% --- PLOTTING SETUP FOR PUBLICATION ---\n",
    "mpl.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Computer Modern Roman\"], # Or \"Times New Roman\"\n",
    "    \"font.size\": 12,\n",
    "    \"axes.labelsize\": 14,\n",
    "    \"xtick.labelsize\": 12,\n",
    "    \"ytick.labelsize\": 12,\n",
    "    \"legend.fontsize\": 11,\n",
    "    # High-quality backend for saving figures\n",
    "    'pgf.texsystem': 'pdflatex',\n",
    "    'pgf.preamble': r'\\usepackage[utf8x]{inputenc}\\usepackage[T1]{fontenc}',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    \"base_directory\": \"/scratch/egomez/irrigation_project_output/models\",\n",
    "    \"smoothing_window\": 21,\n",
    "    \"smoothing_polyorder\": 5,\n",
    "    \"output_dir\": \"./plots\",\n",
    "\n",
    "    # Regex captures algo, chance, and days as separate named groups.\n",
    "    \"model_name_pattern\": re.compile(\n",
    "        r\"exp\\d+_(?P<algo>DDPG|SAC|DDPGLagrangian|SACLagrangian)_chance_\"\n",
    "        r\"(?P<chance>[\\d\\.]+)_\"\n",
    "        r\"(?P<days>days\\d+)\"\n",
    "        r\"(?:_s(?P<seed>\\d+))?\" # Seed is optional in the name itself\n",
    "    ),\n",
    "\n",
    "    # Tag mapping remains the same.\n",
    "    \"tag_mapping\": {\n",
    "        'Averageworker/EpRet': 'Return (Training)',\n",
    "        'Averageworker/EpNumViolations': 'Number of Violations (Training)',\n",
    "        \n",
    "        'Averageeval/TestEpRet': 'Return (Evaluation)',\n",
    "        'Averageeval/TestEpNumViolations': 'Number of Violations (Evaluation)',\n",
    "\n",
    "        'Stdworker/EpRet': 'Return Std (Training)',\n",
    "        'Stdworker/EpNumViolations': 'Number of Violations Std (Training)',\n",
    "\n",
    "        'Stdeval/TestEpRet': 'Return Std (Evaluation)',\n",
    "        'Stdeval/TestEpNumViolations': 'Number of Violations Std (Evaluation)',\n",
    "    },\n",
    "\n",
    "    # Style map uses different colors.\n",
    "    \"plot_styles\": {\n",
    "        'SAC':  {'color': '#1f77b4', 'linestyle': '-', 'label': 'SAC'},\n",
    "        'DDPG': {'color': '#ff7f0e', 'linestyle': '-', 'label': 'DDPG'},\n",
    "\n",
    "        'SACLagrangian': {\n",
    "            '1.0':  {'color': '#2ca02c', 'linestyle': '-', 'label': r'SAC Lagrangian ($\\alpha=1.0$)'},\n",
    "            '0.95': {'color': '#d62728', 'linestyle': '-', 'label': r'SAC Lagrangian ($\\alpha=0.95$)'},\n",
    "            '0.85': {'color': '#9467bd', 'linestyle': '-', 'label': r'SAC Lagrangian ($\\alpha=0.85$)'},\n",
    "            '0.75': {'color': '#8c564b', 'linestyle': '-', 'label': r'SAC Lagrangian ($\\alpha=0.75$)'},\n",
    "        },\n",
    "        'DDPGLagrangian': {\n",
    "            '1.0':  {'color': '#e377c2', 'linestyle': '-', 'label': r'DDPG Lagrangian ($\\alpha=1.0$)'},\n",
    "            '0.95': {'color': '#7f7f7f', 'linestyle': '-', 'label': r'DDPG Lagrangian ($\\alpha=0.95$)'},\n",
    "            '0.85': {'color': '#bcbd22', 'linestyle': '-', 'label': r'DDPG Lagrangian ($\\alpha=0.85$)'},\n",
    "            '0.75': {'color': '#17becf', 'linestyle': '-', 'label': r'DDPG Lagrangian ($\\alpha=0.75$)'},\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(CONFIG['output_dir'], exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_model_info(dir_name: str) -> dict | None:\n",
    "    \"\"\"\n",
    "    Parses a directory name using the detailed regex from CONFIG.\n",
    "    \"\"\"\n",
    "    match = CONFIG[\"model_name_pattern\"].search(dir_name)\n",
    "    if not match:\n",
    "        return None\n",
    "    \n",
    "    info = match.groupdict()\n",
    "    \n",
    "    # Create a unique name for this specific configuration\n",
    "    experiment_name = f\"{info['algo']}_chance{info['chance']}_{info['days']}\"\n",
    "    info['name'] = experiment_name\n",
    "    \n",
    "    return info\n",
    "\n",
    "\n",
    "def process_scalar_data(tb_path: str) -> pd.DataFrame | None:\n",
    "    \"\"\"\n",
    "    Loads scalar data from a single TensorBoard directory.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ea = event_accumulator.EventAccumulator(tb_path, size_guidance={event_accumulator.SCALARS: 0})\n",
    "        ea.Reload()\n",
    "        if not ea.Tags().get('scalars'): return None\n",
    "\n",
    "        ref_tag = 'Averageeval/TestEpRet'\n",
    "        if ref_tag not in ea.Tags()['scalars']: return None\n",
    "        \n",
    "        data = {'TrainingSteps': [e.step for e in ea.Scalars(ref_tag)]}\n",
    "        for tag, col_name in CONFIG[\"tag_mapping\"].items():\n",
    "            if tag in ea.Tags()['scalars']:\n",
    "                values = [e.value for e in ea.Scalars(tag)]\n",
    "                if len(values) == len(data['TrainingSteps']):\n",
    "                    data[col_name] = values\n",
    "        \n",
    "        return pd.DataFrame(data)\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error processing {tb_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_all_runs(base_dir: str) -> dict:\n",
    "    \"\"\"\n",
    "    Scans base directory, loads TensorBoard data, and groups it by experiment.\n",
    "    \n",
    "    Returns a dictionary where each entry contains the raw dataframes (dfs)\n",
    "    and the parsed metadata (info) for that experiment.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(base_dir):\n",
    "        raise FileNotFoundError(f\"Directory not found: {base_dir}\")\n",
    "\n",
    "    # Use a defaultdict to simplify initialization\n",
    "    grouped_data = defaultdict(lambda: {\"dfs\": [], \"info\": {}})\n",
    "    \n",
    "    tb_paths = [os.path.join(root, \"tb\") for root, dirs, _ in os.walk(base_dir) if \"tb\" in dirs]\n",
    "\n",
    "    print(f\"Found {len(tb_paths)} potential TensorBoard directories. Processing...\")\n",
    "\n",
    "    for tb_path in tqdm(tb_paths, desc=\"Loading runs\"):\n",
    "        model_dir_with_seed = os.path.basename(os.path.dirname(tb_path))\n",
    "        parent_dir = os.path.basename(os.path.dirname(os.path.dirname(tb_path)))\n",
    "        \n",
    "        model_info = parse_model_info(parent_dir)\n",
    "        if not model_info:\n",
    "            model_info = parse_model_info(model_dir_with_seed)\n",
    "\n",
    "        if not model_info:\n",
    "            continue\n",
    "            \n",
    "        df = process_scalar_data(tb_path)\n",
    "        if df is not None and not df.empty:\n",
    "            exp_name = model_info['name']\n",
    "            grouped_data[exp_name][\"dfs\"].append(df)\n",
    "            grouped_data[exp_name][\"info\"] = model_info\n",
    "            \n",
    "    return dict(grouped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Load and process data from all TensorBoard logs\n",
    "all_model_data = load_all_runs(CONFIG[\"base_directory\"])\n",
    "\n",
    "# Print a summary of the loaded data\n",
    "print(\"\\n--- Data Loading Summary ---\")\n",
    "if not all_model_data:\n",
    "    print(\"✗ No data was loaded. Check your CONFIG settings and directory structure.\")\n",
    "else:\n",
    "    for name, data in sorted(all_model_data.items()):\n",
    "        print(f\"- Experiment '{name}': Found {len(data['dfs'])} runs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_metric(ax: plt.Axes, mean_metric_name: str, std_metric_name: str, day_data: dict, config: dict,\n",
    "                       scale_factor: float = 1.0):\n",
    "    \"\"\"\n",
    "    Helper function to plot data with improved legend ordering.\n",
    "    Updated to group first by alpha value, then by algorithm.\n",
    "    \"\"\"\n",
    "    # Create a function to manually sort the legend entries\n",
    "    def get_legend_order(algo, chance=None):\n",
    "        # Order: First regular algorithms (DDPG, SAC)\n",
    "        if 'Lagrangian' not in algo:\n",
    "            # Regular algorithms - DDPG first (0), then SAC (1)\n",
    "            return 0 if algo == 'DDPG' else 1\n",
    "        \n",
    "        # For Lagrangian variants, first group by alpha value, then by algorithm\n",
    "        # Start from position 2 (after regular algorithms)\n",
    "        if chance == '0.75':\n",
    "            base = 2\n",
    "        elif chance == '0.85':\n",
    "            base = 4\n",
    "        elif chance == '0.95':\n",
    "            base = 6\n",
    "        elif chance == '1.0':\n",
    "            base = 8\n",
    "        else:\n",
    "            base = 10  # Fallback\n",
    "        \n",
    "        # For each alpha group, DDPG first, then SAC\n",
    "        if 'DDPG' in algo:\n",
    "            return base\n",
    "        else:  # SAC\n",
    "            return base + 1\n",
    "    \n",
    "    # First sort the items by our custom order for plotting\n",
    "    sorted_items = []\n",
    "    \n",
    "    # Extract info and sort by our custom ordering\n",
    "    for exp_name, exp_data in day_data.items():\n",
    "        info = exp_data['info']\n",
    "        algo = info['algo']\n",
    "        chance = info.get('chance', None)\n",
    "        order = get_legend_order(algo, chance)\n",
    "        sorted_items.append((order, (exp_name, exp_data)))\n",
    "    \n",
    "    # Sort by our custom order\n",
    "    sorted_items.sort()\n",
    "    \n",
    "    # Now plot in the sorted order\n",
    "    max_steps = 0\n",
    "    for _, (exp_name, exp_data) in sorted_items:\n",
    "        info, dfs = exp_data['info'], exp_data['dfs']\n",
    "        if not dfs: continue\n",
    "\n",
    "        all_runs_df = pd.concat(dfs).sort_values(by='TrainingSteps').reset_index(drop=True)\n",
    "        if not all_runs_df.empty:\n",
    "            max_steps = max(max_steps, all_runs_df['TrainingSteps'].max())\n",
    "\n",
    "        # Check if the pre-calculated std data is available\n",
    "        if std_metric_name in all_runs_df.columns:\n",
    "            agg_df = all_runs_df.groupby('TrainingSteps')[[mean_metric_name, std_metric_name]].mean().reset_index()\n",
    "            std_values = agg_df[std_metric_name]\n",
    "            mean_values = agg_df[mean_metric_name]\n",
    "        else:\n",
    "            # Fallback if no pre-calculated std is found\n",
    "            print(f\"Warning: Std metric '{std_metric_name}' not found. Calculating std across seeds.\")\n",
    "            agg_df = all_runs_df.groupby('TrainingSteps')[mean_metric_name].agg(['mean', 'std']).reset_index()\n",
    "            agg_df.columns = ['TrainingSteps', 'mean', 'std']\n",
    "            std_values = agg_df['std'].fillna(0)\n",
    "            mean_values = agg_df['mean']\n",
    "\n",
    "        # Only smooth the mean values, not the standard deviation\n",
    "        mean_smooth = savgol_filter(mean_values, config['smoothing_window'], config['smoothing_polyorder'])\n",
    "        # Ensure std values are non-negative but DON'T smooth them\n",
    "        std_values = np.maximum(std_values, 0)\n",
    "\n",
    "        style_group = config['plot_styles'].get(info['algo'], {})\n",
    "        style = style_group.get(info['chance'], {}) if 'Lagrangian' in info['algo'] else style_group\n",
    "        color, linestyle, label = style.get('color', 'gray'), style.get('linestyle', '-'), style.get('label', exp_name)\n",
    "\n",
    "        ax.plot(agg_df['TrainingSteps'], mean_smooth, label=label, color=color, linestyle=linestyle, linewidth=1.5)\n",
    "        ax.fill_between(agg_df['TrainingSteps'], mean_smooth - std_values, mean_smooth + std_values, alpha=0.15, color=color)\n",
    "\n",
    "    ax.set_ylabel(mean_metric_name)\n",
    "    ax.grid(True, which='both', linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "    ax.xaxis.set_major_formatter(mpl.ticker.FuncFormatter(lambda x, p: f'{x / scale_factor:.1f}'))\n",
    "    return max_steps\n",
    "\n",
    "# This function now displays each figure in the notebook before closing it.\n",
    "def plot_publication_figures(data: dict, config: dict):\n",
    "    \"\"\"\n",
    "    Generates a multi-page PDF with one page for Evaluation and one for Training data.\n",
    "    \"\"\"\n",
    "    data_by_day = defaultdict(dict)\n",
    "    for exp_name, exp_data in data.items():\n",
    "        data_by_day[exp_data['info']['days']][exp_name] = exp_data\n",
    "\n",
    "    if not data_by_day:\n",
    "        print(\"No data to plot.\")\n",
    "        return\n",
    "\n",
    "    save_path = os.path.join(config['output_dir'], 'performance_grid.pdf')\n",
    "    with PdfPages(save_path) as pdf:\n",
    "        print(f\"\\n--- Generating multi-page PDF: {save_path} ---\")\n",
    "\n",
    "        for metric_type in [\"Evaluation\", \"Training\"]:\n",
    "            print(f\"  -> Plotting page for {metric_type} data...\")\n",
    "            day_keys = sorted(data_by_day.keys())\n",
    "            n_rows, n_cols = len(day_keys), 2\n",
    "\n",
    "            fig, axes = plt.subplots(n_rows, n_cols, figsize=(10, 4 * n_rows), squeeze=False)\n",
    "            fig.suptitle(fr'\\textbf{{Performance Metrics ({metric_type})}}', fontsize=16, y=0.96)\n",
    "\n",
    "            for i, day in enumerate(day_keys):\n",
    "                day_data = data_by_day[day]\n",
    "                day_number = day.replace('days', '')\n",
    "                ax_return, ax_violations = axes[i, 0], axes[i, 1]\n",
    "\n",
    "                # Determine scale\n",
    "                temp_max_steps = 0\n",
    "                for exp_data in day_data.values():\n",
    "                    for df in exp_data['dfs']:\n",
    "                        if not df.empty:\n",
    "                            temp_max_steps = max(temp_max_steps, df['TrainingSteps'].max())\n",
    "                \n",
    "                if temp_max_steps > 1.5e6: scale_factor, scale_label = 1e6, r'($\\times 10^6$)'\n",
    "                elif temp_max_steps > 1.5e3: scale_factor, scale_label = 1e3, r'($\\times 10^3$)'\n",
    "                else: scale_factor, scale_label = 1.0, ''\n",
    "\n",
    "                # --- THIS IS THE FIX ---\n",
    "                # Explicitly define all metric names to avoid errors.\n",
    "                return_mean_metric = f'Return ({metric_type})'\n",
    "                return_std_metric = f'Return Std ({metric_type})'\n",
    "                violations_mean_metric = f'Number of Violations ({metric_type})'\n",
    "                violations_std_metric = f'Number of Violations Std ({metric_type})'\n",
    "                \n",
    "                # Pass both mean and std names to the plotting function.\n",
    "                plot_single_metric(ax_return, return_mean_metric, return_std_metric, day_data, config, scale_factor=scale_factor)\n",
    "                plot_single_metric(ax_violations, violations_mean_metric, violations_std_metric, day_data, config, scale_factor=scale_factor)\n",
    "\n",
    "                # Set labels and titles\n",
    "                ax_return.set_ylabel(f'$d={day_number}$', fontsize=12)\n",
    "                ax_violations.set_ylabel('')\n",
    "                if i == 0:\n",
    "                    ax_return.set_title(r'\\textbf{Return}', fontsize=14)\n",
    "                    ax_violations.set_title(r'\\textbf{Number of Violations}', fontsize=14)\n",
    "\n",
    "                row_xlabel = f'Training Steps {scale_label}'\n",
    "                ax_return.set_xlabel(row_xlabel, fontsize=14)\n",
    "                ax_violations.set_xlabel(row_xlabel, fontsize=14)\n",
    "\n",
    "            # The legend order is now correct for BOTH plots because it's handled properly in plot_single_metric.\n",
    "            handles, labels = axes[0, 0].get_legend_handles_labels()\n",
    "            n_variants = len(handles) // 2 if len(handles) > 0 else 5\n",
    "            fig.legend(handles, labels, loc='lower center', bbox_to_anchor=(0.5, 0.01),\n",
    "                    ncol=n_variants, frameon=False, title=r'\\textbf{Model}', \n",
    "                    fontsize=10, title_fontsize=14)\n",
    "            \n",
    "            fig.tight_layout(rect=[0, 0.08, 1, 0.98], h_pad=2.0, w_pad=1.0)\n",
    "            \n",
    "            pdf.savefig(fig, bbox_inches='tight')\n",
    "            display(fig)\n",
    "            plt.close(fig)\n",
    "\n",
    "    print(f\"✅ Multi-page figure saved to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And finally, call the new function in your execution cell:\n",
    "plot_publication_figures(all_model_data, CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_metric_chance95(ax: plt.Axes, mean_metric_name: str, std_metric_name: str, day_data: dict, config: dict,\n",
    "                       scale_factor: float = 1.0):\n",
    "    \"\"\"\n",
    "    A new version of the plotting function that ONLY plots regular models\n",
    "    and Lagrangian models with chance=0.95.\n",
    "    \"\"\"\n",
    "\n",
    "    filtered_day_data = {}\n",
    "    for exp_name, exp_data in day_data.items():\n",
    "        info = exp_data['info']\n",
    "        algo = info['algo']\n",
    "        chance = info.get('chance', None)\n",
    "        \n",
    "        # Define the conditions for which models to keep\n",
    "        is_regular = 'Lagrangian' not in algo\n",
    "        is_chance_95_lagrangian = 'Lagrangian' in algo and chance == '0.95'\n",
    "        \n",
    "        # If the model meets either condition, add it to our new dictionary\n",
    "        if is_regular or is_chance_95_lagrangian:\n",
    "            filtered_day_data[exp_name] = exp_data\n",
    "\n",
    "    # Create a function to manually sort the legend entries\n",
    "    def get_legend_order(algo, chance=None):\n",
    "        # Order: First regular algorithms (DDPG, SAC)\n",
    "        if 'Lagrangian' not in algo:\n",
    "            # Regular algorithms - DDPG first (0), then SAC (1)\n",
    "            return 0 if algo == 'DDPG' else 1\n",
    "        \n",
    "        # For Lagrangian variants, first group by alpha value, then by algorithm\n",
    "        # Start from position 2 (after regular algorithms)\n",
    "        if chance == '0.95':\n",
    "            base = 2\n",
    "        else:\n",
    "            base = 4  # Fallback\n",
    "        \n",
    "        # For each alpha group, DDPG first, then SAC\n",
    "        if 'DDPG' in algo:\n",
    "            return base\n",
    "        else:  # SAC\n",
    "            return base + 1\n",
    "    \n",
    "    # First sort the items by our custom order for plotting\n",
    "    sorted_items = []\n",
    "    \n",
    "    # Extract info and sort by our custom ordering\n",
    "    for exp_name, exp_data in filtered_day_data.items():\n",
    "        info = exp_data['info']\n",
    "        algo = info['algo']\n",
    "        chance = info.get('chance', None)\n",
    "        order = get_legend_order(algo, chance)\n",
    "        sorted_items.append((order, (exp_name, exp_data)))\n",
    "    \n",
    "    # Sort by our custom order\n",
    "    sorted_items.sort()\n",
    "    \n",
    "    # Now plot in the sorted order\n",
    "    max_steps = 0\n",
    "    for _, (exp_name, exp_data) in sorted_items:\n",
    "        info, dfs = exp_data['info'], exp_data['dfs']\n",
    "        if not dfs: continue\n",
    "\n",
    "        all_runs_df = pd.concat(dfs).sort_values(by='TrainingSteps').reset_index(drop=True)\n",
    "        if not all_runs_df.empty:\n",
    "            max_steps = max(max_steps, all_runs_df['TrainingSteps'].max())\n",
    "\n",
    "        # Check if the pre-calculated std data is available\n",
    "        if std_metric_name in all_runs_df.columns:\n",
    "            agg_df = all_runs_df.groupby('TrainingSteps')[[mean_metric_name, std_metric_name]].mean().reset_index()\n",
    "            std_values = agg_df[std_metric_name]\n",
    "            mean_values = agg_df[mean_metric_name]\n",
    "        else:\n",
    "            # Fallback if no pre-calculated std is found\n",
    "            print(f\"Warning: Std metric '{std_metric_name}' not found. Calculating std across seeds.\")\n",
    "            agg_df = all_runs_df.groupby('TrainingSteps')[mean_metric_name].agg(['mean', 'std']).reset_index()\n",
    "            agg_df.columns = ['TrainingSteps', 'mean', 'std']\n",
    "            std_values = agg_df['std'].fillna(0)\n",
    "            mean_values = agg_df['mean']\n",
    "\n",
    "        # Only smooth the mean values, not the standard deviation\n",
    "        mean_smooth = savgol_filter(mean_values, config['smoothing_window'], config['smoothing_polyorder'])\n",
    "        # Ensure std values are non-negative but DON'T smooth them\n",
    "        std_values = np.maximum(std_values, 0)\n",
    "\n",
    "        style_group = config['plot_styles'].get(info['algo'], {})\n",
    "        style = style_group.get(info['chance'], {}) if 'Lagrangian' in info['algo'] else style_group\n",
    "        color, linestyle, label = style.get('color', 'gray'), style.get('linestyle', '-'), style.get('label', exp_name)\n",
    "\n",
    "        ax.plot(agg_df['TrainingSteps'], mean_smooth, label=label, color=color, linestyle=linestyle, linewidth=1.5)\n",
    "        ax.fill_between(agg_df['TrainingSteps'], mean_smooth - std_values, mean_smooth + std_values, alpha=0.15, color=color)\n",
    "\n",
    "    ax.set_ylabel(mean_metric_name)\n",
    "    ax.grid(True, which='both', linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "    ax.xaxis.set_major_formatter(mpl.ticker.FuncFormatter(lambda x, p: f'{x / scale_factor:.1f}'))\n",
    "    return max_steps\n",
    "\n",
    "# This function now displays each figure in the notebook before closing it.\n",
    "def plot_publication_figures_chance95(data: dict, config: dict):\n",
    "    \"\"\"\n",
    "    Generates a multi-page PDF with one page for Evaluation and one for Training data.\n",
    "    \"\"\"\n",
    "    data_by_day = defaultdict(dict)\n",
    "    for exp_name, exp_data in data.items():\n",
    "        data_by_day[exp_data['info']['days']][exp_name] = exp_data\n",
    "\n",
    "    if not data_by_day:\n",
    "        print(\"No data to plot.\")\n",
    "        return\n",
    "\n",
    "    save_path = os.path.join(config['output_dir'], 'performance_grid_chance95.pdf')\n",
    "    with PdfPages(save_path) as pdf:\n",
    "        print(f\"\\n--- Generating multi-page PDF: {save_path} ---\")\n",
    "\n",
    "        for metric_type in [\"Evaluation\", \"Training\"]:\n",
    "            print(f\"  -> Plotting page for {metric_type} data...\")\n",
    "            day_keys = sorted(data_by_day.keys())\n",
    "            n_rows, n_cols = len(day_keys), 2\n",
    "\n",
    "            fig, axes = plt.subplots(n_rows, n_cols, figsize=(10, 4 * n_rows), squeeze=False)\n",
    "            fig.suptitle(fr'\\textbf{{Performance Metrics ({metric_type})}}', fontsize=16, y=0.96)\n",
    "\n",
    "            for i, day in enumerate(day_keys):\n",
    "                day_data = data_by_day[day]\n",
    "                day_number = day.replace('days', '')\n",
    "                ax_return, ax_violations = axes[i, 0], axes[i, 1]\n",
    "\n",
    "                # Determine scale\n",
    "                temp_max_steps = 0\n",
    "                for exp_data in day_data.values():\n",
    "                    for df in exp_data['dfs']:\n",
    "                        if not df.empty:\n",
    "                            temp_max_steps = max(temp_max_steps, df['TrainingSteps'].max())\n",
    "                \n",
    "                if temp_max_steps > 1.5e6: scale_factor, scale_label = 1e6, r'($\\times 10^6$)'\n",
    "                elif temp_max_steps > 1.5e3: scale_factor, scale_label = 1e3, r'($\\times 10^3$)'\n",
    "                else: scale_factor, scale_label = 1.0, ''\n",
    "\n",
    "                # --- THIS IS THE FIX ---\n",
    "                # Explicitly define all metric names to avoid errors.\n",
    "                return_mean_metric = f'Return ({metric_type})'\n",
    "                return_std_metric = f'Return Std ({metric_type})'\n",
    "                violations_mean_metric = f'Number of Violations ({metric_type})'\n",
    "                violations_std_metric = f'Number of Violations Std ({metric_type})'\n",
    "                \n",
    "                # Pass both mean and std names to the plotting function.\n",
    "                plot_single_metric_chance95(ax_return, return_mean_metric, return_std_metric, day_data, config, scale_factor=scale_factor)\n",
    "                plot_single_metric_chance95(ax_violations, violations_mean_metric, violations_std_metric, day_data, config, scale_factor=scale_factor)\n",
    "\n",
    "                # Set labels and titles\n",
    "                ax_return.set_ylabel(f'$d={day_number}$', fontsize=12)\n",
    "                ax_violations.set_ylabel('')\n",
    "                if i == 0:\n",
    "                    ax_return.set_title(r'\\textbf{Return}', fontsize=14)\n",
    "                    ax_violations.set_title(r'\\textbf{Number of Violations}', fontsize=14)\n",
    "\n",
    "                row_xlabel = f'Training Steps {scale_label}'\n",
    "                ax_return.set_xlabel(row_xlabel, fontsize=14)\n",
    "                ax_violations.set_xlabel(row_xlabel, fontsize=14)\n",
    "\n",
    "            # The legend order is now correct for BOTH plots because it's handled properly in plot_single_metric.\n",
    "            handles, labels = axes[0, 0].get_legend_handles_labels()\n",
    "            n_variants = len(handles) // 2 if len(handles) > 0 else 5\n",
    "            fig.legend(handles, labels, loc='lower center', bbox_to_anchor=(0.5, 0.01),\n",
    "                    ncol=n_variants, frameon=False, title=r'\\textbf{Model}', \n",
    "                    fontsize=12, title_fontsize=14)\n",
    "            \n",
    "            fig.tight_layout(rect=[0, 0.08, 1, 0.98], h_pad=2.0, w_pad=1.0)\n",
    "            \n",
    "            pdf.savefig(fig, bbox_inches='tight')\n",
    "            display(fig)\n",
    "            plt.close(fig)\n",
    "\n",
    "    print(f\"✅ Multi-page figure saved to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And finally, call the new function in your execution cell:\n",
    "plot_publication_figures_chance95(all_model_data, CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIMULATION_CONSTANTS = {\n",
    "    's_star': 0.35, # Target Soil Moisture\n",
    "    'sfc': 0.65,    # Field Capacity\n",
    "    'sw': 0.3      # Wilting Point\n",
    "}\n",
    "\n",
    "def plot_simulation(df, title, save_path, constants):\n",
    "    \"\"\"\n",
    "    Reads simulation data from a pandas DataFrame and creates an enhanced,\n",
    "    publication-quality plot with correctly layered elements.\n",
    "    \"\"\"\n",
    "    plt.style.use('seaborn-v0_8-paper')\n",
    "\n",
    "    # --- 1. Define the Color Palette ---\n",
    "    history_It = df[\"History It (before scaling)\"] * 1000\n",
    "    history_Rain = df[\"History Rainfall\"]\n",
    "    history_st = df[\"History Soil Moisture\"]\n",
    "    days = np.arange(len(history_st))\n",
    "\n",
    "    color_moisture = \"#0D7607\"\n",
    "    color_rain = \"#1916ED\"\n",
    "    color_irrigation = \"#4B3633\"\n",
    "    color_feasible_zone = \"#B5E6B8\"\n",
    "    color_chance_zone = \"#FFB46E\"\n",
    "    color_hard_zone = \"#FD9286\"\n",
    "\n",
    "    # --- 2. Create the Plot and Axes ---\n",
    "    fig, ax1 = plt.subplots(figsize=(14, 6))\n",
    "    bar_width = 0.25\n",
    "    ax2 = ax1.twinx()\n",
    "\n",
    "    # --- 3. Add Shaded Background Zones with LOWER alpha ---\n",
    "    ax2.axhspan(0, constants['sw'], color=color_hard_zone, alpha=0.3, label='Hard-Constrained Zone', zorder=0)\n",
    "    ax2.axhspan(constants['sw'], constants['s_star'], color=color_chance_zone, alpha=0.3, label='Chance-Constrained Zone', zorder=0)\n",
    "    ax2.axhspan(constants['s_star'], constants['sfc'], color=color_feasible_zone, alpha=0.3, label='Feasible Zone', zorder=0)\n",
    "    ax2.axhspan(constants['sfc'], 1, color=color_chance_zone, alpha=0.3, label='Chance-Constrained Zone', zorder=0)\n",
    "\n",
    "    # --- 4. Plot the Main Data with specific layer orders ---\n",
    "    # Make sure bars are drawn on the correct axis (ax1) with higher zorder\n",
    "    rain_bars = ax1.bar(days - bar_width/2, history_Rain, width=bar_width, color=color_rain, \n",
    "                        label='Rainfall (mm)', zorder=5)\n",
    "    irrigation_bars = ax1.bar(days + bar_width/2, history_It, width=bar_width, color=color_irrigation, \n",
    "                              label='Irrigation (mm)', zorder=5)\n",
    "    \n",
    "    # Horizontal lines\n",
    "    ax2.axhline(y=constants['sfc'], color=\"#BC850E\", linestyle='--', \n",
    "                label=r'Field Capacity ($s_{fc}$)', linewidth=1.5, zorder=2)\n",
    "    ax2.axhline(y=constants['s_star'], color=\"#7746D9\", linestyle='--', \n",
    "                label=r'Target ($s^*$)', linewidth=1.5, zorder=2)\n",
    "    ax2.axhline(y=constants['sw'], color=\"#9F4500\", linestyle='--', \n",
    "                label=r'Wilting Point ($s_{w}$)', linewidth=1.5, zorder=2)\n",
    "    \n",
    "    # The main soil moisture line goes on top of everything\n",
    "    moisture_line = ax2.plot(days, history_st, color=color_moisture, \n",
    "                             label='Soil Moisture', linewidth=1.5, zorder=6)[0]\n",
    "\n",
    "    # --- 5. Formatting and Legend ---\n",
    "    ax1.set_xlabel(r'Day', fontsize=14)\n",
    "    ax1.set_ylabel(r'Precipitation \\& Irrigation (mm)', fontsize=14, color=color_rain)  # Blue color to match rain\n",
    "    ax2.set_ylabel(r'Soil Moisture Level', fontsize=14, color=color_moisture)\n",
    "    ax1.set_ylim(0, max(np.max(history_Rain), np.max(history_It)) * 1.25 if len(history_It) > 0 else 10)\n",
    "    ax2.set_ylim(0, 1)\n",
    "\n",
    "    # Ensure ax1 (precipitation axis) is drawn in front of ax2 (moisture axis)\n",
    "    ax1.set_zorder(10)\n",
    "    ax1.patch.set_visible(False)  # This makes ax1's background transparent\n",
    "\n",
    "    ax1.tick_params(axis='y', labelsize=12, colors=color_rain)  # Blue for rainfall axis\n",
    "    ax1.tick_params(axis='x', labelsize=12)\n",
    "    ax2.tick_params(axis='y', labelsize=12, colors=color_moisture)\n",
    "    ax1.spines['top'].set_visible(False)\n",
    "    ax2.spines['top'].set_visible(False)\n",
    "    ax2.grid(True, which='major', axis='y', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "    plt.title(title, fontsize=18)\n",
    "\n",
    "    # Create THREE SEPARATE LEGEND ROWS with manual grouping\n",
    "    # First row: Time series data\n",
    "    legend1_items = [\n",
    "        (moisture_line, 'Soil Moisture'),\n",
    "        (rain_bars, 'Rainfall (mm)'),\n",
    "        (irrigation_bars, 'Irrigation (mm)')\n",
    "    ]\n",
    "    \n",
    "    # Second row: Threshold lines  \n",
    "    legend2_items = [\n",
    "        (ax2.get_lines()[0], r'Field Capacity ($s_{fc} = 0.65$)'),  # Field capacity line\n",
    "        (ax2.get_lines()[1], r'Water Stress Point ($s^* = 0.35$)'),             # Target line\n",
    "        (ax2.get_lines()[2], r'Permanent Wilting Point ($s_{w} = 0.3$)')     # Wilting point line\n",
    "    ]\n",
    "    \n",
    "    # Third row: Zones\n",
    "    legend3_items = [\n",
    "        (plt.Rectangle((0, 0), 1, 1, fc=color_feasible_zone, alpha=0.3), 'Feasible Region'),\n",
    "        (plt.Rectangle((0, 0), 1, 1, fc=color_chance_zone, alpha=0.3), 'Chance-Constrained Region'),\n",
    "        (plt.Rectangle((0, 0), 1, 1, fc=color_hard_zone, alpha=0.3), 'Hard-Constrained Region')\n",
    "    ]\n",
    "    \n",
    "    # Unpack each legend group\n",
    "    handles1, labels1 = zip(*legend1_items)\n",
    "    handles2, labels2 = zip(*legend2_items)\n",
    "    handles3, labels3 = zip(*legend3_items)\n",
    "    \n",
    "    # Place three separate legends at different vertical positions\n",
    "    fig.legend(handles1, labels1, loc='lower center', bbox_to_anchor=(0.5, 0.02), \n",
    "               ncol=len(handles1), frameon=False, fontsize=12)\n",
    "               \n",
    "    fig.legend(handles2, labels2, loc='lower center', bbox_to_anchor=(0.5, -0.03), \n",
    "               ncol=len(handles2), frameon=False, fontsize=12)\n",
    "               \n",
    "    fig.legend(handles3, labels3, loc='lower center', bbox_to_anchor=(0.5, -0.08), \n",
    "               ncol=len(handles3), frameon=False, fontsize=12)\n",
    "\n",
    "    # Adjust the bottom margin to make room for all three legend rows\n",
    "    fig.tight_layout(rect=[0, 0.15, 1, 0.95])\n",
    "    \n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"  -> Saved plot to {save_path}\")\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "    \n",
    "def batch_plot_simulations(base_dir, episode_to_plot, config):\n",
    "    \"\"\"\n",
    "    Finds and plots all simulation CSVs for a specific episode,\n",
    "    saving them as PDFs to the main output directory.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Searching for simulation data for Episode {episode_to_plot} ---\")\n",
    "    \n",
    "    # --- CHANGE #1: Use the output directory from your CONFIG ---\n",
    "    output_plot_dir = config['output_dir']\n",
    "    os.makedirs(output_plot_dir, exist_ok=True) # Ensure it exists\n",
    "    \n",
    "    # Use os.walk to search all subdirectories robustly\n",
    "    for root, dirs, files in os.walk(base_dir):\n",
    "        csv_filename = f\"simulation_data_episode{episode_to_plot}.csv\"\n",
    "        \n",
    "        if csv_filename in files:\n",
    "            csv_path = os.path.join(root, csv_filename)\n",
    "            model_dir_name = os.path.basename(root)\n",
    "            \n",
    "            print(f\"\\nFound data for: {model_dir_name}\")\n",
    "            \n",
    "            try:\n",
    "                df = pd.read_csv(csv_path)\n",
    "                model_info = parse_model_info(model_dir_name)\n",
    "                \n",
    "                if model_info:\n",
    "                    algo = model_info['algo']\n",
    "                    chance = model_info['chance']\n",
    "                    day_num = model_info['days'].replace('days', '')\n",
    "\n",
    "                    display_algo = algo.replace('DDPGLagrangian', 'DDPG Lagrangian').replace('SACLagrangian', 'SAC Lagrangian')\n",
    "                    \n",
    "                    if 'Lagrangian' in algo:\n",
    "                        title = fr'\\textbf{{{display_algo} ($\\alpha={chance}$, $d={day_num}$) | Evaluation Episode (Seed 59)}}'\n",
    "                    else:\n",
    "                        title = fr'\\textbf{{{display_algo} ($d={day_num}$) | Evaluation Episode (Seed 59)}}'\n",
    "                else:\n",
    "                    title = fr'\\textbf{{{model_dir_name} - Evaluation Episode (Seed 59)}}'\n",
    "\n",
    "                # Save as .pdf ---\n",
    "                save_filename = f\"simulation_{model_dir_name}_e{episode_to_plot}.pdf\"\n",
    "                save_path = os.path.join(output_plot_dir, save_filename)\n",
    "                \n",
    "                plot_simulation(df, title, save_path, SIMULATION_CONSTANTS)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"  -> ERROR processing {csv_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose which episode you want to generate plots for\n",
    "EPISODE_TO_PLOT = 499 \n",
    "\n",
    "batch_plot_simulations(CONFIG[\"base_directory\"], episode_to_plot=EPISODE_TO_PLOT, config=CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# =============================================================================\n",
    "# CELL 2: CORE PLOTTING HELPER FUNCTION\n",
    "# =============================================================================\n",
    "def populate_simulation_axes(ax1, df, constants):\n",
    "    \"\"\"\n",
    "    This is the core plotting logic, which draws all elements onto a given subplot axis (ax1).\n",
    "    \"\"\"\n",
    "    # --- 1. Extract Data and Define Colors ---\n",
    "    history_It = df[\"History It (before scaling)\"] * 1000\n",
    "    history_Rain = df[\"History Rainfall\"]\n",
    "    history_st = df[\"History Soil Moisture\"]\n",
    "    days = np.arange(len(history_st))\n",
    "\n",
    "    color_moisture = \"#0D7607\"\n",
    "    color_rain = \"#1916ED\"\n",
    "    color_irrigation = \"#4B3633\"\n",
    "    color_feasible_zone = \"#B5E6B8\"\n",
    "    color_chance_zone = \"#FFB46E\"\n",
    "    color_hard_zone = \"#FD9286\"\n",
    "    \n",
    "    bar_width = 0.25\n",
    "    ax2 = ax1.twinx()\n",
    "\n",
    "    # --- 2. Add Shaded Background Zones ---\n",
    "    ax2.axhspan(0, constants['sw'], color=color_hard_zone, alpha=0.3, label='Hard-Constrained Region', zorder=0)\n",
    "    ax2.axhspan(constants['sw'], constants['s_star'], color=color_chance_zone, alpha=0.3, label='Chance-Constrained Region', zorder=0)\n",
    "    ax2.axhspan(constants['s_star'], constants['sfc'], color=color_feasible_zone, alpha=0.3, label='Feasible Region', zorder=0)\n",
    "    ax2.axhspan(constants['sfc'], 1, color=color_chance_zone, alpha=0.3, label='Chance-Constrained Region', zorder=0)\n",
    "\n",
    "    # --- 3. Plot the Main Data ---\n",
    "    rain_bars = ax1.bar(days - bar_width/2, history_Rain, width=bar_width, color=color_rain, label='Rainfall (mm)', zorder=5)\n",
    "    irrigation_bars = ax1.bar(days + bar_width/2, history_It, width=bar_width, color=color_irrigation, label='Irrigation (mm)', zorder=5)\n",
    "    \n",
    "    ax2.axhline(y=constants['sfc'], color=\"#BC850E\", linestyle='--', label=r'Field Capacity ($s_{fc}$)', linewidth=1.5, zorder=2)\n",
    "    ax2.axhline(y=constants['s_star'], color=\"#7746D9\", linestyle='--', label=r'Target ($s^*$)', linewidth=1.5, zorder=2)\n",
    "    ax2.axhline(y=constants['sw'], color=\"#9F4500\", linestyle='--', label=r'Permanent Wilting Point ($s_{w}$)', linewidth=1.5, zorder=2)\n",
    "    \n",
    "    moisture_line = ax2.plot(days, history_st, color=color_moisture, label='Soil Moisture', linewidth=1, zorder=6)[0]\n",
    "\n",
    "    # --- 4. Formatting ---\n",
    "    ax1.set_ylabel(r'Precipitation \\& Irrigation (mm)', fontsize=14, color=color_rain)\n",
    "    ax2.set_ylabel(r'Soil Moisture Level', fontsize=14, color=color_moisture)\n",
    "    ax1.set_ylim(0, max(np.max(history_Rain), np.max(history_It)) * 1.25 if len(history_It) > 0 else 10)\n",
    "    ax2.set_ylim(0, 1)\n",
    "\n",
    "    ax1.set_zorder(10)\n",
    "    ax1.patch.set_visible(False)\n",
    "\n",
    "    ax1.tick_params(axis='y', labelsize=12, colors=color_rain)\n",
    "    ax1.tick_params(axis='x', labelsize=12)\n",
    "    ax2.tick_params(axis='y', labelsize=12, colors=color_moisture)\n",
    "    ax1.spines['top'].set_visible(False)\n",
    "    ax2.spines['top'].set_visible(False)\n",
    "    ax2.grid(True, which='major', axis='y', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "    # Return the handles and labels needed for the shared legend\n",
    "    return moisture_line, rain_bars, irrigation_bars, ax2.get_lines()\n",
    "\n",
    "# %%\n",
    "# =============================================================================\n",
    "# CELL 3: MAIN SIMULATION PLOTTING FUNCTION\n",
    "# =============================================================================\n",
    "def plot_all_days_comparison(base_dir, episode_to_plot, config):\n",
    "    \"\"\"\n",
    "    Creates a multi-page PDF, where each page is a 2x2 grid comparing\n",
    "    regular and chance=0.95 models for a specific day configuration (d=1, 3, 7).\n",
    "    \"\"\"\n",
    "    # 1. Find all unique 'day_key's available in the data\n",
    "    day_keys = set()\n",
    "    for root, dirs, files in os.walk(base_dir):\n",
    "        model_info = parse_model_info(os.path.basename(root))\n",
    "        if model_info:\n",
    "            day_keys.add(model_info['days'])\n",
    "\n",
    "    if not day_keys:\n",
    "        print(\"No model data found to plot.\")\n",
    "        return\n",
    "\n",
    "    # 2. Initialize the multi-page PDF file\n",
    "    save_path = os.path.join(config['output_dir'], f'simulation_comparison_all_days_e{episode_to_plot}.pdf')\n",
    "    with PdfPages(save_path) as pdf:\n",
    "        print(f\"\\n--- Creating multi-page comparison PDF: {save_path} ---\")\n",
    "\n",
    "        # 3. Loop through each day_key to create one page per day\n",
    "        for day_key in sorted(list(day_keys)):\n",
    "            print(f\"  -> Plotting page for {day_key}...\")\n",
    "\n",
    "            # Find the four specific model data files for this day_key\n",
    "            models_to_find = {'DDPG': None, 'SAC': None, 'DDPG Lagrangian': None, 'SAC Lagrangian': None}\n",
    "            for root, dirs, files in os.walk(base_dir):\n",
    "                if day_key not in root:\n",
    "                    continue\n",
    "                \n",
    "                csv_filename = f\"simulation_data_episode{episode_to_plot}.csv\"\n",
    "                if csv_filename in files:\n",
    "                    model_info = parse_model_info(os.path.basename(root))\n",
    "                    if not model_info: continue\n",
    "\n",
    "                    is_regular = 'Lagrangian' not in model_info['algo']\n",
    "                    is_chance_95 = 'Lagrangian' in model_info['algo'] and model_info['chance'] == '0.95'\n",
    "                    key = model_info['algo'].replace('DDPGLagrangian', 'DDPG Lagrangian').replace('SACLagrangian', 'SAC Lagrangian')\n",
    "\n",
    "                    if is_regular and key in models_to_find:\n",
    "                        models_to_find[key] = (os.path.join(root, csv_filename), model_info['chance'])\n",
    "                    elif is_chance_95 and key in models_to_find:\n",
    "                        models_to_find[key] = (os.path.join(root, csv_filename), model_info['chance'])\n",
    "\n",
    "            # Create the 2x2 figure grid for the current page\n",
    "            fig, axes = plt.subplots(2, 2, figsize=(14, 10), sharex=True)\n",
    "            plot_map = {(0, 0): 'DDPG', (0, 1): 'SAC', (1, 0): 'DDPG Lagrangian', (1, 1): 'SAC Lagrangian'}\n",
    "\n",
    "            # Populate each subplot\n",
    "            for (row, col), model_name in plot_map.items():\n",
    "                ax = axes[row, col]\n",
    "                found_data = models_to_find.get(model_name)\n",
    "                \n",
    "                if found_data and os.path.exists(found_data[0]):\n",
    "                    csv_path, chance_val = found_data\n",
    "                    df = pd.read_csv(csv_path)\n",
    "                    moisture_line, rain_bars, irrigation_bars, ax2_lines = populate_simulation_axes(ax, df, SIMULATION_CONSTANTS)\n",
    "                    \n",
    "                    if model_name.endswith('Lagrangian'):\n",
    "                        title_name = fr'{model_name} ($\\alpha={chance_val}$)'\n",
    "                    else:\n",
    "                        title_name = f'{model_name} (Regular)'\n",
    "                    ax.set_title(fr'\\textbf{{{title_name}}}', fontsize=16)\n",
    "                else:\n",
    "                    ax.text(0.5, 0.5, f'Data not found for\\n{model_name}', ha='center', va='center', fontsize=12)\n",
    "                    ax.set_xticks([]); ax.set_yticks([])\n",
    "\n",
    "            axes[1, 0].set_xlabel(r'Day', fontsize=14)\n",
    "            axes[1, 1].set_xlabel(r'Day', fontsize=14)\n",
    "\n",
    "            # Create the shared, three-row legend for the current page\n",
    "            legend1_items = [(moisture_line, 'Soil Moisture'), (rain_bars, 'Rainfall (mm)'), (irrigation_bars, 'Irrigation (mm)')]\n",
    "            legend2_items = [(ax2_lines[0], r'Field Capacity ($s_{fc} = 0.65$)'), (ax2_lines[1], r'Water Stress Point ($s^* = 0.35$)'), (ax2_lines[2], r'Permanent Wilting Point ($s_{w} = 0.3$)')]\n",
    "            legend3_items = [(plt.Rectangle((0, 0), 1, 1, fc=\"#B5E6B8\", alpha=0.3), 'Feasible Region'), (plt.Rectangle((0, 0), 1, 1, fc=\"#FFB46E\", alpha=0.3), 'Chance-Constrained Region'), (plt.Rectangle((0, 0), 1, 1, fc=\"#FD9286\", alpha=0.3), 'Hard-Constrained Region')]\n",
    "            \n",
    "            handles1, labels1 = zip(*legend1_items)\n",
    "            handles2, labels2 = zip(*legend2_items)\n",
    "            handles3, labels3 = zip(*legend3_items)\n",
    "            \n",
    "            # Place three separate legends at different vertical positions\n",
    "            fig.legend(handles1, labels1, loc='lower center', bbox_to_anchor=(0.5, 0.03), \n",
    "                       ncol=len(handles1), frameon=False, fontsize=12)\n",
    "                       \n",
    "            fig.legend(handles2, labels2, loc='lower center', bbox_to_anchor=(0.5, 0.0), \n",
    "                       ncol=len(handles2), frameon=False, fontsize=12)\n",
    "                       \n",
    "            fig.legend(handles3, labels3, loc='lower center', bbox_to_anchor=(0.5, -0.03), \n",
    "                       ncol=len(handles3), frameon=False, fontsize=12)\n",
    "\n",
    "            # Add overall title for the page\n",
    "            day_number = day_key.replace('days', '')\n",
    "            page_title = f\"Model Performance During Evaluation, Seed 59 ($d={day_number}$)\"\n",
    "            fig.suptitle(fr'\\textbf{{{page_title}}}', fontsize=18, y=0.98)\n",
    "            \n",
    "            # Adjust layout to make room for all three legend rows\n",
    "            fig.tight_layout(rect=[0, 0.1, 1, 0.99], h_pad=1.5, w_pad=1.0)\n",
    "            \n",
    "            # Save to PDF and show in notebook\n",
    "            pdf.savefig(fig, bbox_inches='tight')\n",
    "            display(fig)\n",
    "            plt.close(fig)\n",
    "\n",
    "    print(f\"✅ Multi-page figure saved to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the episode you want to compare across all day configurations\n",
    "EPISODE_TO_PLOT = 499\n",
    "\n",
    "plot_all_days_comparison(CONFIG[\"base_directory\"],\n",
    "                         episode_to_plot=EPISODE_TO_PLOT,\n",
    "                         config=CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_simulation_stats(df, constants):\n",
    "    \"\"\"\n",
    "    Calculate key statistics from a simulation dataframe.\n",
    "    \"\"\"\n",
    "    # Convert the irrigation to mm (multiply by 1000)\n",
    "    irrigation_mm = df[\"History It (before scaling)\"] * 1000\n",
    "    soil_moisture = df[\"History Soil Moisture\"]\n",
    "    \n",
    "    # Calculate key statistics\n",
    "    total_irrigation = irrigation_mm.sum()\n",
    "    \n",
    "    # Calculate probabilities\n",
    "    total_days = len(soil_moisture)\n",
    "    days_above_s_star = sum(soil_moisture >= constants['s_star'])\n",
    "    days_below_sw = sum(soil_moisture < constants['sw'])\n",
    "    days_below_sfc = sum(soil_moisture <= constants['sfc'])\n",
    "    days_above_sfc = sum(soil_moisture > constants['sfc'])\n",
    "    days_above_sw = sum(soil_moisture >= constants['sw'])\n",
    "    days_below_sw = sum(soil_moisture < constants['sw'])\n",
    "    \n",
    "    # Convert to probabilities\n",
    "    prob_above_s_star = days_above_s_star / total_days\n",
    "    prob_below_sfc = days_below_sfc / total_days\n",
    "    prob_above_sw = days_above_sw / total_days\n",
    "    \n",
    "    # Number of violations = absolute count of days with violations\n",
    "    num_violations = days_below_sw + days_above_sfc + days_above_sfc\n",
    "    \n",
    "    # The return should be available in the dataframe if it was stored\n",
    "    episode_return = df[\"Episode Return\"].iloc[-1] if \"Episode Return\" in df.columns else None\n",
    "    \n",
    "    return {\n",
    "        \"total_irrigation_mm\": total_irrigation,\n",
    "        \"prob_above_s_star\": prob_above_s_star,\n",
    "        \"prob_below_sfc\": prob_below_sfc,\n",
    "        \"prob_above_sw\": prob_above_sw,\n",
    "        \"num_violations\": num_violations,\n",
    "        \"episode_return\": episode_return\n",
    "    }\n",
    "\n",
    "def print_all_simulation_stats(base_dir, episode_to_analyze, constants):\n",
    "    \"\"\"\n",
    "    Finds all simulation CSV files for a specific episode and prints their statistics.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Statistics for Episode {episode_to_analyze} ---\")\n",
    "    print(\"| Model | Day | α | Total Irrigation (mm) | P(s ≥ s*) | P(s ≥ sw) | P(s > sfc) | Violations | Return |\")\n",
    "    print(\"|-------|-----|---|---------------------|-----------|-----------|------------|-----------|--------|\")\n",
    "    \n",
    "    # Create a list to store all results for later DataFrame creation\n",
    "    all_stats = []\n",
    "    \n",
    "    # Use os.walk to search all subdirectories\n",
    "    for root, dirs, files in os.walk(base_dir):\n",
    "        csv_filename = f\"simulation_data_episode{episode_to_analyze}.csv\"\n",
    "        \n",
    "        if csv_filename in files:\n",
    "            csv_path = os.path.join(root, csv_filename)\n",
    "            model_dir_name = os.path.basename(root)\n",
    "            \n",
    "            try:\n",
    "                df = pd.read_csv(csv_path)\n",
    "                model_info = parse_model_info(model_dir_name)\n",
    "                \n",
    "                if model_info:\n",
    "                    algo = model_info['algo']\n",
    "                    chance = model_info['chance']\n",
    "                    day_num = model_info['days'].replace('days', '')\n",
    "                    \n",
    "                    display_algo = algo.replace('DDPGLagrangian', 'DDPG-L').replace('SACLagrangian', 'SAC-L')\n",
    "                    \n",
    "                    # Calculate statistics\n",
    "                    stats = calculate_simulation_stats(df, constants)\n",
    "                    \n",
    "                    # If return is not found in the CSV, try to get it from TensorBoard\n",
    "                    if stats['episode_return'] is None:\n",
    "                        # Look for the tensorboard directory\n",
    "                        tb_path = os.path.join(root, \"tb\")\n",
    "                        if os.path.exists(tb_path):\n",
    "                            try:\n",
    "                                ea = event_accumulator.EventAccumulator(tb_path)\n",
    "                                ea.Reload()\n",
    "                                \n",
    "                                # Look for evaluation return data\n",
    "                                if 'Averageeval/TestEpRet' in ea.Tags().get('scalars', []):\n",
    "                                    # Get the last evaluation return value\n",
    "                                    stats['episode_return'] = ea.Scalars('Averageeval/TestEpRet')[-1].value\n",
    "                                    print(f\"  -> Found return from TensorBoard for {model_dir_name}: {stats['episode_return']:.1f}\")\n",
    "                            except Exception as e:\n",
    "                                print(f\"  -> Could not read TensorBoard data: {e}\")\n",
    "                    \n",
    "                    # Add to results list\n",
    "                    all_stats.append({\n",
    "                        'Model': display_algo,\n",
    "                        'Days': int(day_num),\n",
    "                        'Alpha': chance,\n",
    "                        'Total Irrigation (mm)': stats['total_irrigation_mm'],\n",
    "                        'P(s ≥ s*)': stats['prob_above_s_star'],\n",
    "                        'P(s ≥ sw)': stats['prob_above_sw'],\n",
    "                        'P(s ≤ sfc)': stats['prob_below_sfc'],\n",
    "                        'Violations': stats['num_violations'],\n",
    "                        'Return': stats['episode_return']\n",
    "                    })\n",
    "                    \n",
    "                    # Format the return value for display\n",
    "                    if stats['episode_return'] is not None:\n",
    "                        return_str = f\"{stats['episode_return']:.1f}\"\n",
    "                    else:\n",
    "                        return_str = \"N/A\"\n",
    "                        \n",
    "                    # Print as Markdown table row\n",
    "                    print(f\"| {display_algo} | {day_num} | {chance} | {stats['total_irrigation_mm']:.2f} | \"\n",
    "                          f\"{stats['prob_above_s_star']:.3f} | {stats['prob_above_sw']:.3f} | \"\n",
    "                          f\"{1-stats['prob_below_sfc']:.3f} | {stats['num_violations']} | \"\n",
    "                          f\"{return_str} |\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"  -> ERROR processing {csv_path}: {e}\")\n",
    "    \n",
    "    # Create a DataFrame with all the statistics\n",
    "    if all_stats:\n",
    "        stats_df = pd.DataFrame(all_stats)\n",
    "        # Sort by Days, then Alpha, then Model\n",
    "        stats_df = stats_df.sort_values(by=['Days', 'Alpha', 'Model'])\n",
    "        \n",
    "        # Save to CSV\n",
    "        stats_csv_path = os.path.join(CONFIG['output_dir'], f'simulation_stats_e{episode_to_analyze}.csv')\n",
    "        stats_df.to_csv(stats_csv_path, index=False)\n",
    "        print(f\"\\nStatistics saved to: {stats_csv_path}\")\n",
    "        \n",
    "        return stats_df\n",
    "    else:\n",
    "        print(\"No statistics were calculated.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose which episode you want to analyze\n",
    "EPISODE_TO_ANALYZE = 499\n",
    "\n",
    "# Calculate and print statistics\n",
    "stats_df = print_all_simulation_stats(CONFIG[\"base_directory\"], \n",
    "                                     episode_to_analyze=EPISODE_TO_ANALYZE,\n",
    "                                     constants=SIMULATION_CONSTANTS)\n",
    "\n",
    "# Display the dataframe in the notebook (optional)\n",
    "if stats_df is not None:\n",
    "    display(stats_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "irrigation_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
